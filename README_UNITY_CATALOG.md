# Unity Catalog

![alt text](UNITY_CATALOG_IMAGES/image-5-v.png)


### Curso: Udemy - Azure Databricks end to end project with Unity Catalog CI/CD

<p align="center">
  <blockquote>
Atua como uma interface unificada para os workspaces em rela√ß√£o a User Management, Metastore, Acess Controls.  
E tamb√©m pode ver quem tem acesso a qu√™. Tem Acess Control, Lineage, Discovery, Monitoring, Auditing, Sharing.  
Facilita o gerenciamento e governan√ßa principalmente quando tenho v√°rios workspaces e tenho que centralizar o permissionamento.
  </blockquote>
</p>

![alt text](UNITY_CATALOG_IMAGES/image-1.png)

![alt text](UNITY_CATALOG_IMAGES/image-2.png)

## Databricks Access Connector

O Databricks Access Connector, um servi√ßo que funciona como identidade gerenciada para permitir que o Unity Catalog / Metastore tenha acesso centralizado ao Azure Data Lake Gen2.

Como o Unity Catalog n√£o √© um recurso do Azure e n√£o pode receber permiss√µes diretamente via IAM, √© necess√°rio criar uma identidade gerenciada ‚Äî o Databricks Access Connector.
Depois, essa identidade recebe o papel Storage Blob Data Contributor na conta de armazenamento.

Assim, o Unity Catalog poder√° usar essa identidade para acessar o Data Lake e criar o Metastore, que √© onde ser√£o armazenadas tabelas gerenciadas e configura√ß√µes de governan√ßa.

![alt text](UNITY_CATALOG_IMAGES/image-3.png)

Passos do v√≠deo:

1. Criar o Databricks Access Connector.

* Obs: Quando √© criado um workspace no databricks j√° e criado um access connector denominado: unity-catalog-access-connector, ent√£o se n√£o desejar, n√£o precisa criar um novo.

- Copie o Resource ID depois que foi criado

<img src="UNITY_CATALOG_IMAGES/image-7.png" width="50%">
<img src="UNITY_CATALOG_IMAGES/image-4.png" width="70%">

2. Atribuir a ele o papel Storage Blob Data Contributor no ADLS Gen2.

<img src="UNITY_CATALOG_IMAGES/image-5.png" width="70%">

3. Esse ID ser√° usado depois para criar o Metastore no Unity Catalog.

![alt text](UNITY_CATALOG_IMAGES/image-2-v.png)

---

Para o databricks com UC, primeiramente eu preciso de Databricks Premium Workspace onde tamb√©m e necess√°rio configurar um metastore. Portanto, ao configurar o metastore, ele nos perguntar√° o local onde pode armazenar
as tabelas gerenciadas. Ao criar um metastore voc√™ precisa 
anex√°-lo a um workspace.

* Para ter acesso ao console account √© necess√°rio ser um account admin. O que significa que a cria√ß√£o do workspace n√£o √© suficiente para dar a voc√™ o papel de Account Admin.

* Em resumo: O Administrador Global do Microsoft Entra ID torna-se o primeiro Account Admin do Databricks, mas essa associa√ß√£o n√£o √© autom√°tica para todos os Global Admins. Ap√≥s a cria√ß√£o, o Global Admin pode (e deve) delegar a fun√ß√£o de Account Admin do Databricks para o usu√°rio final apropriado e, se quiser, remover a fun√ß√£o de si mesmo.

Vamos l√°

1. Crie um metastore(Esse metastore precisa est√° na mesma regi√£o que todas suas contas de armazenamento - ideal, workspace):
![alt text](UNITY_CATALOG_IMAGES/image-7-v.png)

![alt text](UNITY_CATALOG_IMAGES/image-v.png)

![alt text](UNITY_CATALOG_IMAGES/image-3-v.png)

* Voc√™ pode criar um metastore por regi√£o, n√£o √© poss√≠vel criar v√°rios metastores para uma √∫nica regi√£o.

* O par√¢metro ADLS Gen2 path √© opcional se n√£o estiver forcendo o caminho neste momento, enquanto estiver criando
objetos como esquema, cat√°logos ou tabelas, voc√™ precisar√° fornecer o caminho ali. (Esse caminho serve para armazenar tabelas gerenciadas desse metastore espec√≠fico)

2. Anexe ao Workspace

![alt text](UNITY_CATALOG_IMAGES/image-1-v.png)

# O Escopo da Conta Databricks (vs. Azure Subscription)

Antes do UC: O controle de acesso (ACLs, Contributor/Reader) era feito no n√≠vel da Assinatura Azure. Se voc√™ n√£o estivesse na assinatura, n√£o tinha acesso ao Workspace.

Com o UC: O Databricks Account Console e o Metastore operam no n√≠vel do Tenant (Locat√°rio) do Microsoft Entra ID.

Um √∫nico Tenant do Azure pode ter v√°rias Assinaturas e, consequentemente, v√°rios Workspaces espalhados por essas assinaturas.

O Account Console do Databricks tem visibilidade de todos os Workspaces dentro desse Tenant (independentemente da Assinatura ou Grupo de Recursos em que foram criados).

Isso permite que voc√™ anexe Workspaces de diferentes Assinaturas a um √∫nico Metastore, centralizando o controle de acesso e os metadados para toda a organiza√ß√£o (Tenant).

Em suma, o Unity Catalog oferece uma camada de governan√ßa universal que se estende por todos os seus Workspaces, elevando o gerenciamento do n√≠vel do Workspace/Assinatura para o n√≠vel da Conta Databricks (que corresponde ao Tenant do Azure).

![alt text](UNITY_CATALOG_IMAGES/image-4-v.png)

## Roles no Unity Catalog

![alt text](UNITY_CATALOG_IMAGES/image-6-v.png)

## Atribuindo permiss√µes via Microsft Entra ID

1. Crie um usu√°rio de exemplo para testar as permiss√µes no UC.

![alt text](UNITY_CATALOG_IMAGES/image-8-v.png)

Usu√°rio 1 - Jarvis (Workspace Admin) - Password: Mo@34633493 </br>
Usu√°rio 2 - Steve (Developers) -  Password: Mo@34633493

2. Criado os usu√°rios no Microsoft Entra ID √© necess√°rio adicion√°-los no UC

![alt text](UNITY_CATALOG_IMAGES/image-9-v.png)

* Obs: Na pr√°tica real voc√™ far√° isso por meio do provisionamento de usu√°rios, em que voc√™
adiciona o seu provedor de identidade e vai sincrizar com todos os seus usu√°rios da organiza√ß√£o.

![alt text](UNITY_CATALOG_IMAGES/image-10-v.png)

## User and Group Management

1. Adicionar os usu√°rios no UC

![alt text](UNITY_CATALOG_IMAGES/image_k.png)

2. Criar grupos no UC
- Workspace Admins
- Developers

![alt text](UNITY_CATALOG_IMAGES/image-1_k.png)

3. Dar as roles necess√°rias para cada grupo
 - Wokspace Admin - Workspace Admins Group
 - Wokspace User - Developers Group

 ![alt text](UNITY_CATALOG_IMAGES/image-2_k.png)

 * Permiss√£o no n√≠vel admin, permite gerenciar grupos de usu√°rios e a configura√ß√£o do workspace. A permiss√£o no n√≠vel user d√° a permiss√£o do usu√°rio apenas acessar o workspace, criar coisas como schema, tabelas e pode ser propriet√°rio dessas tabelas.

 Como estamos utilizando a databricks e ele n√£o e necess√°rio um servi√ßo da Azure, o usu√°rio n√£o precisa ter acesso a nenhuma assinatura, apenas o link do workspace.

 ![alt text](UNITY_CATALOG_IMAGES/image-3_k.png)

Se eu quiser desativar a cria√ß√£o de personal compute, para todos os usu√°rios, fa√ßa isso:

![alt text](UNITY_CATALOG_IMAGES/image-4_k.png)

Agora o usu√°rio Steve n√£o consegue criar um personal compute.

## Cluster Policy

Cluster policy √© util para controlar a capacidade dos usu√°rios de configurar o cluster com base em determinadas regras. Portanto, essas regras especificam quais atributos ou valores de atributos podem ser usados durante a cria√ß√£o do cluster. E, com base nas pol√≠ticas de cluster, ele t√™m algo como regras de controle de acesso que podem limitar os usu√°rios e grupos espec√≠ficos.

* Obs: Com a permiss√£o de Workspace Admin eu posso liberar para um usu√°rio espec√≠fico conseguir criar um cluster.

![alt text](UNITY_CATALOG_IMAGES/image-5_k.png)

1. No console compute -> policies -> create policy -> Atribua um nome a policy -> Em familiy posso pegar modelos para me basear e criar a minha pr√≥pria policy.

* Obs: O workspace admin vai poder criar cluster com base em v√°rias policy, ent√£o quando quiser criar a policy para determinado usu√°rio, crie um grupo sem ter a permiss√£o de Admin e depois cria a policy para cria√ß√£o de cluster.

* An√°lise o terraform para verificar como criar policy por meio de IaC

* Voc√™ n√£o pode usar inst√¢ncias spot para o n√≥ do driver em um cluster do Azure Databricks, o que se aplica diretamente a clusters de n√≥ √∫nico (que consistem apenas no n√≥ do driver). 

# Cluster Pools

Podem ser utilizados para limitar a cria√ß√£o de usu√°rios a um determinado tipo de inst√¢ncia ou para determinado grupo,
por√©m permite um tempo de inicializa√ß√£o mais r√°pido por conta que defino o m√≠nimo inst√¢ncias igual a 1.

Ent√£o eu posso criar um pool com max instances = 2 e coloco min_idle = 1, por√©m nas permiss√µes eu posso atribuir, por exemplo,
que meu grupo de developers acesse esse pool ai quando ele da um create cluster na sele√ß√£o de cluster ele seleciona o nome do meu pool de forma que vai criar mais uma inst√¢ncia chegando ao m√°ximo que √© 2, por√©m o tempo de inicializa√ß√£o e bem r√°pido.

No cluster policy eu posso criar uma defini√ß√£o por exemplo para meus usu√°rios criarem m√°quinas apenas do meu pool.

1. Copio o pool id

![alt text](UNITY_CATALOG_IMAGES/image-6_k.png)

2. Atribuo no value do Json

![alt text](UNITY_CATALOG_IMAGES/image-7_k.png)

## Padr√µes de workspace para o databricks

Em geral, voc√™ pode considerar a cria√ß√£o de um cat√°logo para cada ambiente, no qual cada 
ambiente pode ser criado em um √∫nico cat√°logo. Ou seja, pode haver um cat√°logo de desenvolvimento, um cat√°logo de UAT e um cat√°logo de produ√ß√£o.

![alt text](UNITY_CATALOG_IMAGES/image_w.png)

* Onde P1, P2 ... significam projetos/workspaces

* OBS: Workspace Admin n√£o possuem acessos para criar cat√°logos por default, ent√£o √© necess√°rio atribuir essa permiss√£o. S√≥ um ponto de aten√ß√£o no terraform talvez na primeira execu√ß√£o de erro na aplica√ß√£o de policy no grupo developer, onde vai ser necess√°rio anexar o grupo ao workspace antes de executar novamente, pode dar algum erro novamente, mas aguarde uns minutos de o terraform plan que vai ser sucesso.

Para um usu√°rio trabalhar com o cat√°logo e necess√°rio dar a permiss√£o `USE CATALOG` ela permite que os usu√°rios visualizem o catal√≥go apesar de n√£o realizar nenhuma a√ß√£o.

Query para ver inform√ß√µes do metastore como exemplo, onde fica as tabelas armazenadas por padr√£o (managed).

`SELECT
  *
FROM
  system.information_schema.metastores`

## Instala√ß√£o de libs externas 

Para instala√ß√£o de bibliotecas de modo nativo no cluster voc√™ pode utilizar cluster policy que nem foi realizado no terraform. Por√©m a databricks por seguran√ßa restringe a esse tipo de instala√ß√£o e para isso foi criado a folder securiy do terraform que libera o acesso para insta√ß√£o da lib `maven`. 

Por√©m para aplicar isso no terraform √© necess√°rio que o User tenha a permiss√£o `MANAGE ALLOWLIST`. 

Para fazer isso v√° at√© catal√≥go e clique no simbolo da ingrenagem e logo ap√≥s clique no nome do metastore.

![alt text](UNITY_CATALOG_IMAGES/image-1_w.png)


Na aba permiss√µes adicione a permiss√£o `MANAGE ALLOWLIST`:

![alt text](UNITY_CATALOG_IMAGES/image-2_w.png)

* Obs: A lib spark-measure s√≥ funciona no modo cluster single-user do databricks.

## Storage Credential & External Location

O Unity Catalog acessa o armazenamento principal (onde ficam as **tabelas gerenciadas**) por meio do **Databricks Access Connector**, usando uma **identidade gerenciada** configurada na cria√ß√£o do **Metastore**. Esse acesso vale apenas para o **cont√™iner raiz** definido nesse momento.

Em cen√°rios reais, √© comum precisar acessar **outras contas de armazenamento** ou **outros cont√™ineres** (inclusive na mesma conta). Esses locais **n√£o s√£o reconhecidos automaticamente** pelo Unity Catalog e, sem configura√ß√£o adicional, geram erros de acesso.

Para resolver isso, o Unity Catalog introduz dois novos objetos:

### üîπ Credencial de Armazenamento (Storage Credential)
- Respons√°vel pela **autentica√ß√£o** no armazenamento.
- Armazena a identidade usada para acesso (preferencialmente **identidade gerenciada** via Databricks Access Connector, ou alternativamente um **Service Principal**).
- Define **‚Äúquem pode acessar‚Äù** o storage.

### üîπ Local Externo (External Location)
- Funciona como um **ponteiro** para um caminho espec√≠fico no armazenamento (ex: um cont√™iner).
- Usa uma **credencial de armazenamento** para obter acesso.
- Define **‚Äúonde est√£o os dados‚Äù**.

### üîπ Diferen√ßa Conceitual
- **Local Externo** ‚Üí guarda o **caminho** do armazenamento.
- **Credencial de Armazenamento** ‚Üí guarda a **autentica√ß√£o/acesso**.
- Ambos s√£o necess√°rios: **saber o caminho n√£o √© suficiente sem permiss√£o**.

### üîπ Benef√≠cio Principal
Esses dois objetos permitem que o Unity Catalog forne√ßa **controle de acesso centralizado e refinado**, possibilitando acessar m√∫ltiplos storages ou cont√™ineres de forma segura e sem credenciais embutidas em notebooks.

> A Databricks recomenda fortemente o uso de **identidades gerenciadas**, evitando segredos e autentica√ß√£o manual.

![alt text](UNITY_CATALOG_IMAGES/image-3_w.png)

1. Primeira etapa √© criar uma credential

![alt text](UNITY_CATALOG_IMAGES/image-4_w.png)

2. Selecione service credential

![alt text](UNITY_CATALOG_IMAGES/image-5_w.png)

3. De um nome (Credential Name - Modulo no terraform chamado storage_credential) e o Acess Connector ID √© o valor do Resource ID do Databricks Acess Conector. Lembrando que √© ness√°rio dar a role de contributor para storage account que voc√™ deseja acessar.

4. Para criar uma external location apenas clique em cat√°logo e External Locations. Ir√° aparece metastore_root_location que e o local das suas tabelas gerenciadas definida no metastore e voc√™ pode criar uma nova external location se necess√°rio utilizando a credential criada anteriormente.

![alt text](UNITY_CATALOG_IMAGES/image-6_w.png)

![alt text](UNITY_CATALOG_IMAGES/image-7_w.png)

* Obs: A cri√ß√£o via terraform do external location pode ser visualizado no modulo external_location.
